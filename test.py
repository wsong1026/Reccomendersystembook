# AUTOGENERATED! DO NOT EDIT! File to edit: 99_example.ipynb.

# %% auto 0
__all__ = []

# %% 99_example.ipynb 2
from datetime import datetime

import streamlit as st

from streamlit_jupyter import StreamlitPatcher, tqdm

import os
import pandas as pd
import seaborn as sns
import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from scipy.sparse import csr_matrix
from sklearn.neighbors import NearestNeighbors


# Get dataset
my_path_books = os.path.join(os.getcwd(), "dataset", "books.csv")
data_books = pd.read_csv(my_path_books, low_memory=False)

my_path_ratings = os.path.join(os.getcwd(), "dataset", "ratings.csv")
data_ratings = pd.read_csv(my_path_ratings, low_memory=False)

my_path_to_read = os.path.join(os.getcwd(), "dataset", "to_read.csv")
data_to_read = pd.read_csv(my_path_to_read, low_memory=False)

# Drop non-related values
combine_book_rating = pd.merge(data_ratings, data_books, on="book_id")
combine_book_rating = combine_book_rating.dropna(axis=0, subset=['title'])
combine_book_rating = combine_book_rating.drop_duplicates(subset=['title', 'user_id'])

book_ratingCount = (combine_book_rating.groupby(by=['title'])['rating']
                    .count()
                    .reset_index()
                    .rename(columns={'rating': 'totalRatingCount'})
                    [['title', 'totalRatingCount']]
                    )

book_ratingCount = pd.merge(book_ratingCount, combine_book_rating[["title", "authors", "image_url", "small_image_url"]], on='title', how='left')
book_ratingCount = book_ratingCount.drop_duplicates(subset=['title']).reset_index(drop=True)

# Save the data to a CSV file
book_ratingCount.to_csv(r'C:\Users\Admin\Desktop\Collaborative Filtering Recommender System\collab.csv')

# Visualization
st.title("Book Recommendation System")

st.subheader("Boxplot of Ratings Count")
st.box_plot(data_books['ratings_count'])

st.subheader("Countplot of Ratings")
sns_countplot = sns.countplot(x="rating", data=data_ratings)
st.pyplot(sns_countplot.figure)

st.subheader("Explicit Ratings")
data = data_ratings[data_ratings['rating'] != 0]
sns_countplot_explicit = sns.countplot(x="rating", data=data)
plt.title("Explicit Ratings")
st.pyplot(sns_countplot_explicit.figure)

# Only considering books with >= 50 ratings
popularity_threshold = 50

rating_popular_books = combine_book_rating.query('totalRatingCount >= @popularity_threshold')

st.subheader("Top Popular Books")
st.dataframe(rating_popular_books.sort_values(by='totalRatingCount', ascending=False).head())

# User-Item Matrix
st.subheader("User-Item Matrix")
books_features_df = rating_popular_books.pivot_table(index='title', columns='user_id', values='rating').fillna(0)
st.dataframe(books_features_df.head())

# Data normalization
st.subheader("Data Normalization")
books_features_norm_df = books_features_df.subtract(books_features_df.mean(axis=1), axis='rows')
st.dataframe(books_features_norm_df.head())

# Import K-Nearest Neighbour
st.subheader("K-Nearest Neighbors Model")
books_features_df_matrix = csr_matrix(books_features_norm_df.values)

model_knn = NearestNeighbors(metric='cosine', algorithm='brute')
model_knn.fit(books_features_df_matrix)

# Collaborative Filtering using K-Nearest Neighbours
st.subheader("Recommend Books Based on User Input")
input_recommendation_amount = st.number_input("Enter the number of books you want for recommendation:", min_value=1, step=1)

input_recommendation_book = st.text_input("Enter books you have read:")

if st.button("Get Recommendations"):
    n_neighbors = input_recommendation_amount + 1

    query_index = np.where(books_features_norm_df.index == input_recommendation_book)[0][0]
    distances, indices = model_knn.kneighbors(books_features_norm_df.iloc[query_index, :].values.reshape(1, -1), n_neighbors)

    recommendations = []
    for i in range(1, len(distances.flatten())):
        book_index = indices.flatten()[i]
        book_title = books_features_norm_df.index[book_index]
        recommendations.append((i, book_index, book_title))

    recommendations_df = pd.DataFrame(recommendations, columns=["#", "Index", "Book Title"])
    recommendations_df.set_index("#", inplace=True)
    st.subheader(f"Recommendations for {input_recommendation_book}:")
    st.dataframe(recommendations_df)

# Recommend a random book for the user by Collaborative Filtering using K-Nearest Neighbours
st.subheader("Recommend a Random Book")
input_recommendation_amount_random = st.number_input("Enter the number of books you want for recommendation:", min_value=1, step=1)

if st.button("Get Random Recommendations"):
    n_neighbors = input_recommendation_amount_random + 1

    query_index = np.random.choice(books_features_norm_df.shape[0])
    distances, indices = model_knn.kneighbors(books_features_norm_df.iloc[query_index, :].values.reshape(1, -1), n_neighbors)

    recommendations = []
    result_index = []
    for i in range(1, len(distances.flatten())):
        book_index = indices.flatten()[i]
        book_title = books_features_norm_df.index[book_index]
        result_index.append(book_index)
        recommendations.append((i, book_index, book_title))

    recommendations_df = pd.DataFrame(recommendations, columns=["#", "Index", "Book Title"])
    recommendations_df.set_index("#", inplace=True)
    st.subheader(f"Random Recommendations for {books_features_norm_df.index[query_index]}:")
    st.dataframe(recommendations_df)